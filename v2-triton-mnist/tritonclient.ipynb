{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triton Client\n",
    "\n",
    "Note: just exploratory code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Http Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "\n",
    "# # Note: not all methods available via Executor\n",
    "# url = \"localhost:8003/seldon/seldon/v2-triton-mnist\"\n",
    "url = \"localhost:8000\"\n",
    "\n",
    "http_triton_client = httpclient.InferenceServerClient(\n",
    "    url=url,\n",
    "    verbose=False,\n",
    "    concurrency=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Server Ready: True\n",
      "Is Server Live: True\n",
      "Server Metadata: {'name': 'triton', 'version': '2.13.0', 'extensions': ['classification', 'sequence', 'model_repository', 'model_repository(unload_dependents)', 'schedule_policy', 'model_configuration', 'system_shared_memory', 'cuda_shared_memory', 'binary_tensor_data', 'statistics']}\n",
      "MNIST model ready: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is Server Ready:\", http_triton_client.is_server_ready())\n",
    "print(\"Is Server Live:\", http_triton_client.is_server_live())\n",
    "print(\"Server Metadata:\", http_triton_client.get_server_metadata())\n",
    "print(\"MNIST model ready:\", http_triton_client.is_model_ready(\"mnist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'mnist', 'versions': ['1'], 'platform': 'tensorflow_savedmodel', 'inputs': [{'name': 'conv2d_input', 'datatype': 'FP32', 'shape': [-1, 28, 28, 1]}], 'outputs': [{'name': 'dense_1', 'datatype': 'FP32', 'shape': [-1, 10]}]}\n"
     ]
    }
   ],
   "source": [
    "print(http_triton_client.get_model_metadata(\"mnist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(http_triton_client.get_model_config(\"mnist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8109936e-03, 1.6749991e-04, 4.3998000e-01, 2.5843871e-03,\n",
       "        2.8441547e-04, 3.8541239e-04, 1.9684564e-03, 7.0706295e-04,\n",
       "        5.4516971e-01, 9.4206532e-04],\n",
       "       [4.1001481e-03, 2.8203041e-04, 3.2225168e-01, 7.0531778e-03,\n",
       "        1.4055093e-03, 5.2019940e-03, 2.2412206e-03, 2.0930546e-03,\n",
       "        6.5015137e-01, 5.2198074e-03],\n",
       "       [2.3214463e-02, 8.1608095e-04, 2.8792626e-01, 9.2498166e-03,\n",
       "        1.8826844e-03, 1.3457134e-02, 1.5644446e-02, 2.6651174e-03,\n",
       "        6.4210683e-01, 3.0372196e-03],\n",
       "       [1.4550821e-03, 3.5082394e-05, 1.4485511e-02, 2.3372934e-04,\n",
       "        3.4631207e-04, 4.3974174e-04, 1.8960210e-04, 2.7477610e-04,\n",
       "        9.8204190e-01, 4.9826084e-04],\n",
       "       [6.3246260e-03, 3.1383260e-04, 3.7626114e-02, 5.0798138e-03,\n",
       "        8.4333651e-04, 5.0137374e-03, 3.2386994e-03, 1.8026867e-03,\n",
       "        9.1177511e-01, 2.7981961e-02]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "binary_data = False\n",
    "\n",
    "inputs = [httpclient.InferInput(\"conv2d_input\", (5, 28, 28, 1), \"FP32\")]\n",
    "inputs[0].set_data_from_numpy(np.random.rand(5, 28, 28, 1).astype(\"float32\"), binary_data=binary_data)\n",
    "outputs = [httpclient.InferRequestedOutput(\"dense_1\", binary_data=binary_data)]\n",
    "\n",
    "\n",
    "result = http_triton_client.infer(\"mnist\", inputs, outputs=outputs)\n",
    "result.as_numpy(\"dense_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grpc Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "\n",
    "# # Note: not all methods available via Executor\n",
    "# headers = {\"seldon\": \"v2-triton-mnist\", \"namespace\": \"seldon\"}\n",
    "# url = \"localhost:8003\"\n",
    "\n",
    "url = \"localhost:8001\"\n",
    "headers = dict()\n",
    "\n",
    "grpc_triton_client = grpcclient.InferenceServerClient(\n",
    "    url=url,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Server Ready: True\n",
      "Is Server Live: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name: \"triton\"\n",
       "version: \"2.13.0\"\n",
       "extensions: \"classification\"\n",
       "extensions: \"sequence\"\n",
       "extensions: \"model_repository\"\n",
       "extensions: \"model_repository(unload_dependents)\"\n",
       "extensions: \"schedule_policy\"\n",
       "extensions: \"model_configuration\"\n",
       "extensions: \"system_shared_memory\"\n",
       "extensions: \"cuda_shared_memory\"\n",
       "extensions: \"binary_tensor_data\"\n",
       "extensions: \"statistics\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Is Server Ready:\", grpc_triton_client.is_server_ready(headers=headers))\n",
    "print(\"Is Server Live:\", grpc_triton_client.is_server_live(headers=headers))\n",
    "grpc_triton_client.get_server_metadata(headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST model ready: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MNIST model ready:\", grpc_triton_client.is_model_ready(\"mnist\", headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"mnist\"\n",
       "versions: \"1\"\n",
       "platform: \"tensorflow_savedmodel\"\n",
       "inputs {\n",
       "  name: \"conv2d_input\"\n",
       "  datatype: \"FP32\"\n",
       "  shape: -1\n",
       "  shape: 28\n",
       "  shape: 28\n",
       "  shape: 1\n",
       "}\n",
       "outputs {\n",
       "  name: \"dense_1\"\n",
       "  datatype: \"FP32\"\n",
       "  shape: -1\n",
       "  shape: 10\n",
       "}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpc_triton_client.get_model_metadata(\"mnist\", headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5252707e-02, 2.6560088e-03, 6.3741118e-01, 2.2145616e-01,\n",
       "        3.6019515e-04, 3.7998840e-02, 7.7487421e-03, 6.9566141e-03,\n",
       "        6.8815462e-02, 1.3439893e-03],\n",
       "       [1.2870033e-02, 9.8890497e-04, 5.9165972e-01, 7.4792365e-03,\n",
       "        3.5227824e-03, 1.1102542e-03, 1.7923594e-03, 9.7923726e-03,\n",
       "        3.6278358e-01, 8.0007548e-03],\n",
       "       [5.8509228e-03, 1.9079042e-04, 3.9114609e-02, 4.9245800e-04,\n",
       "        7.5394701e-04, 2.1845701e-03, 7.2474396e-03, 3.6165887e-04,\n",
       "        9.4347650e-01, 3.2706687e-04],\n",
       "       [8.9087533e-03, 8.0969045e-04, 8.5668162e-02, 3.7207045e-03,\n",
       "        6.1010523e-04, 2.6622151e-03, 1.7552607e-03, 3.2632998e-03,\n",
       "        8.9178741e-01, 8.1442646e-04],\n",
       "       [4.9480617e-02, 1.2994569e-04, 5.2092540e-01, 1.7507779e-03,\n",
       "        1.5797348e-04, 6.0777506e-04, 8.1396336e-04, 2.5525091e-03,\n",
       "        4.2290476e-01, 6.7631720e-04]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [grpcclient.InferInput(\"conv2d_input\", (5, 28, 28, 1), \"FP32\")]\n",
    "inputs[0].set_data_from_numpy(np.random.rand(5, 28, 28, 1).astype(\"float32\"))\n",
    "outputs = [grpcclient.InferRequestedOutput(\"dense_1\")]\n",
    "\n",
    "\n",
    "result = grpc_triton_client.infer(\"mnist\", inputs, outputs=outputs, headers=headers)\n",
    "result.as_numpy(\"dense_1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f90d0a8b54f81c3642b2ee3336e1de55986a3a982587eefc0621499dbdd4a3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
